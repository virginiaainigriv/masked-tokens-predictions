{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-04-06T14:09:02.236436Z","iopub.status.busy":"2023-04-06T14:09:02.235861Z","iopub.status.idle":"2023-04-06T14:09:34.308191Z","shell.execute_reply":"2023-04-06T14:09:34.306601Z","shell.execute_reply.started":"2023-04-06T14:09:02.236403Z"},"id":"tpfTor8EJME1","outputId":"54846509-40a3-4342-f76a-8404cc626a08","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.3)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.13.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.4.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.13.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.2)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.1)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2023.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers\n","!pip install torch\n","!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T14:09:34.312310Z","iopub.status.busy":"2023-04-06T14:09:34.311957Z","iopub.status.idle":"2023-04-06T14:09:37.372056Z","shell.execute_reply":"2023-04-06T14:09:37.370877Z","shell.execute_reply.started":"2023-04-06T14:09:34.312277Z"},"id":"nWnrdQ-iUujn","trusted":true},"outputs":[],"source":["import torch\n","import pandas as pd\n","import os\n","import datasets\n","import math"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T14:09:37.374294Z","iopub.status.busy":"2023-04-06T14:09:37.373517Z","iopub.status.idle":"2023-04-06T14:09:37.380573Z","shell.execute_reply":"2023-04-06T14:09:37.378669Z","shell.execute_reply.started":"2023-04-06T14:09:37.374254Z"},"id":"s1veoydTnOe3","trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-04-06T14:24:04.129560Z","iopub.status.busy":"2023-04-06T14:24:04.128882Z","iopub.status.idle":"2023-04-06T14:24:37.109710Z","shell.execute_reply":"2023-04-06T14:24:37.108591Z","shell.execute_reply.started":"2023-04-06T14:24:04.129521Z"},"id":"Hf_T6qd4128u","outputId":"e1e98660-8004-4285-cad2-ad5ead4c20da","trusted":true},"outputs":[],"source":["from transformers import BertTokenizer, BertForMaskedLM\n","from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","\n","model_name = 'pranaydeeps/Ancient-Greek-BERT'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForMaskedLM.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-04-06T14:24:37.113733Z","iopub.status.busy":"2023-04-06T14:24:37.112790Z","iopub.status.idle":"2023-04-06T14:24:39.269076Z","shell.execute_reply":"2023-04-06T14:24:39.268015Z","shell.execute_reply.started":"2023-04-06T14:24:37.113689Z"},"id":"miVlHHy62W3O","outputId":"cbdc486d-dd2f-4d90-b347-60520f844525","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:123: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"]}],"source":["# load the masked and original sentence files\n","masked_file_path = '/kaggle/working/masked.txt'\n","original_file_path = '/kaggle/working/orignal.txt'\n","\n","# create datasets from the files\n","masked_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=masked_file_path,\n","    block_size=128\n",")\n","\n","original_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=original_file_path,\n","    block_size=128\n",")\n","\n","# create a data collator to batch the data\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=True,\n","    mlm_probability=0.15\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"execution":{"iopub.execute_input":"2023-04-06T16:55:34.394742Z","iopub.status.busy":"2023-04-06T16:55:34.394039Z","iopub.status.idle":"2023-04-06T17:43:50.801426Z","shell.execute_reply":"2023-04-06T17:43:50.800391Z","shell.execute_reply.started":"2023-04-06T16:55:34.394704Z"},"id":"kk2KzxVw2S0J","outputId":"624d897f-45e9-4312-fa90-ae6b13ba17d1","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3140' max='3140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3140/3140 48:15, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>300</td>\n","      <td>1.998900</td>\n","      <td>1.885498</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.885200</td>\n","      <td>1.828121</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.793600</td>\n","      <td>1.793792</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.734800</td>\n","      <td>1.774593</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.717100</td>\n","      <td>1.705026</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.720300</td>\n","      <td>1.713230</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>1.666800</td>\n","      <td>1.703594</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>1.714900</td>\n","      <td>1.685495</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>1.738100</td>\n","      <td>1.708302</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.691100</td>\n","      <td>1.637435</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=3140, training_loss=1.7858183283714733, metrics={'train_runtime': 2896.3678, 'train_samples_per_second': 69.052, 'train_steps_per_second': 1.084, 'total_flos': 1.1880888333122304e+16, 'train_loss': 1.7858183283714733, 'epoch': 20.0})"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["# define the training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    overwrite_output_dir=True,\n","    num_train_epochs=20,\n","    per_device_train_batch_size=64,\n","    per_device_eval_batch_size=64,\n","    logging_steps=20,\n","    save_steps=1000,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    evaluation_strategy='steps',\n","    eval_steps=300\n",")\n","\n","# define the trainer and train the model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=masked_dataset,\n","    eval_dataset=original_dataset\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T17:45:51.112648Z","iopub.status.busy":"2023-04-06T17:45:51.112270Z","iopub.status.idle":"2023-04-06T17:45:51.960618Z","shell.execute_reply":"2023-04-06T17:45:51.957163Z","shell.execute_reply.started":"2023-04-06T17:45:51.112614Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1/tokenizer_config.json',\n"," '/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1/special_tokens_map.json',\n"," '/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1/vocab.txt',\n"," '/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1/added_tokens.json',\n"," '/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1/tokenizer.json')"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained('/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1')\n","tokenizer.save_pretrained('/kaggle/working/fine-tuned-pranaydeeps-ancient-greek-v1')"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"execution":{"iopub.execute_input":"2023-04-06T17:46:24.229068Z","iopub.status.busy":"2023-04-06T17:46:24.228163Z","iopub.status.idle":"2023-04-06T17:46:59.452183Z","shell.execute_reply":"2023-04-06T17:46:59.451097Z","shell.execute_reply.started":"2023-04-06T17:46:24.229033Z"},"id":"UE4ibkU31t6V","outputId":"4bd82969-3f4c-46c1-ad8c-3ec12bd2adf3","trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='149' max='149' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [149/149 00:35]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Perplexity: 5.12\n"]}],"source":["eval_results = trainer.evaluate(original_dataset)\n","\n","'''\n","A lower perplexity score means a better language model, \n","\n","'''\n","\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-04-06T17:47:03.822057Z","iopub.status.busy":"2023-04-06T17:47:03.821699Z","iopub.status.idle":"2023-04-06T17:47:04.479582Z","shell.execute_reply":"2023-04-06T17:47:04.475429Z","shell.execute_reply.started":"2023-04-06T17:47:03.822025Z"},"id":"7HEXnyGEusOc","outputId":"8b90f975-d8be-42f9-b5bf-a481b7d32c22","trusted":true},"outputs":[{"data":{"text/plain":["1445"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T17:47:45.179857Z","iopub.status.busy":"2023-04-06T17:47:45.179392Z","iopub.status.idle":"2023-04-06T17:47:45.190180Z","shell.execute_reply":"2023-04-06T17:47:45.188616Z","shell.execute_reply.started":"2023-04-06T17:47:45.179820Z"},"id":"7yeP9s_FJJE_","trusted":true},"outputs":[],"source":["\n","input = [\n","    \"ὅστις μέν σύ ὦ [MASK] Ἀθηναῖος πάσχω ὑπό ὁ ἐμός κατήγορος οὐ οἶδα\",                                                                                                                 \n","    \"ἐγώ δέ οὖν [MASK] αὐτός ὑπό αὐτός ὀλίγος ἐμαυτοῦ ἐπιλανθάνομαι οὕτως πιθανός λέγω\",                                                                                                                 \n","    \"καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς [MASK]\",                                                                                                                      \n","    \"μάλιστα δέ αὐτός εἷς [MASK] ὁ πολύς ὅς ψεύδω οὗτος ἐν ὅς λέγω ὡς χράω σύ εὐλαβέομαι μή ὑπό ἐγώ ἐξαπατάω ὡς δεινός εἰμί λέγω\",                                                                                                     \n","    \"ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω ἔργον [MASK] μηδέ ὁπωσοῦν φαίνω δεινός λέγω οὗτος ἐγώ δοκέω αὐτός ἀναίσχυντος εἰμί εἰ μή ἄρα δεινός καλέω οὗτος λέγω ὁ ἀληθής λέγω\",\n","    ]\n","y_hat = [\n","    \"ὅστις μέν σύ ὦ ἀνήρ Ἀθηναῖος πάσχω ὑπό ὁ ἐμός κατήγορος οὐ οἶδα\",                                                                                                                 \n","    \"ἐγώ δέ οὖν καί αὐτός ὑπό αὐτός ὀλίγος ἐμαυτοῦ ἐπιλανθάνομαι οὕτως πιθανός λέγω\",                                                                                                                 \n","    \"καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς ἐρῶ\",                                                                                                                      \n","    \"μάλιστα δέ αὐτός εἷς θαυμάζω ὁ πολύς ὅς ψεύδω οὗτος ἐν ὅς λέγω ὡς χράω σύ εὐλαβέομαι μή ὑπό ἐγώ ἐξαπατάω ὡς δεινός εἰμί λέγω\",                                                                                                     \n","    \"ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω ἔργον ἐπειδάν μηδέ ὁπωσοῦν φαίνω δεινός λέγω οὗτος ἐγώ δοκέω αὐτός ἀναίσχυντος εἰμί εἰ μή ἄρα δεινός καλέω οὗτος λέγω ὁ ἀληθής λέγω\",\n","    ]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9ODqTOTnAOy","outputId":"77795074-d1ec-4ee5-9fee-ddfa5259dc26","trusted":true},"outputs":[],"source":["# model.to('cuda')"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.execute_input":"2023-04-04T13:02:27.727158Z","iopub.status.busy":"2023-04-04T13:02:27.726187Z","iopub.status.idle":"2023-04-04T13:02:27.801237Z","shell.execute_reply":"2023-04-04T13:02:27.798773Z","shell.execute_reply.started":"2023-04-04T13:02:27.727108Z"},"id":"cneFwT0fiAat","outputId":"bb3e47b0-8906-43ae-b50b-93f8ecc58bdf","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context_sentence</th>\n","      <th>masked_sentence</th>\n","      <th>original_sentence</th>\n","      <th>predicted_tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ὅστις μέν σύ ὦ ἀνήρ Ἀθηναῖος πάσχω ὑπό ὁ ἐμός ...</td>\n","      <td>ὅστις μέν σύ ὦ [MASK] Ἀθηναῖος πάσχω ὑπό ὁ ἐμό...</td>\n","      <td>ὅστις μέν σύ ὦ ἀνήρ Ἀθηναῖος πάσχω ὑπό ὁ ἐμός ...</td>\n","      <td>[σωκρατης]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ἐγώ δέ οὖν καί αὐτός ὑπό αὐτός ὀλίγος ἐμαυτοῦ ...</td>\n","      <td>ἐγώ δέ οὖν [MASK] αὐτός ὑπό αὐτός ὀλίγος ἐμαυτ...</td>\n","      <td>ἐγώ δέ οὖν καί αὐτός ὑπό αὐτός ὀλίγος ἐμαυτοῦ ...</td>\n","      <td>[και]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς</td>\n","      <td>καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς [MASK]</td>\n","      <td>καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς ἐρῶ</td>\n","      <td>[ουδεις]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>μάλιστα δέ αὐτός εἷς θαυμάζω ὁ πολύς ὅς ψεύδω ...</td>\n","      <td>μάλιστα δέ αὐτός εἷς [MASK] ὁ πολύς ὅς ψεύδω ο...</td>\n","      <td>μάλιστα δέ αὐτός εἷς θαυμάζω ὁ πολύς ὅς ψεύδω ...</td>\n","      <td>[γε]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω...</td>\n","      <td>ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω...</td>\n","      <td>ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω...</td>\n","      <td>[λεγω]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    context_sentence  \\\n","0  ὅστις μέν σύ ὦ ἀνήρ Ἀθηναῖος πάσχω ὑπό ὁ ἐμός ...   \n","1  ἐγώ δέ οὖν καί αὐτός ὑπό αὐτός ὀλίγος ἐμαυτοῦ ...   \n","2              καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς   \n","3  μάλιστα δέ αὐτός εἷς θαυμάζω ὁ πολύς ὅς ψεύδω ...   \n","4  ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω...   \n","\n","                                     masked_sentence  \\\n","0  ὅστις μέν σύ ὦ [MASK] Ἀθηναῖος πάσχω ὑπό ὁ ἐμό...   \n","1  ἐγώ δέ οὖν [MASK] αὐτός ὑπό αὐτός ὀλίγος ἐμαυτ...   \n","2       καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς [MASK]   \n","3  μάλιστα δέ αὐτός εἷς [MASK] ὁ πολύς ὅς ψεύδω ο...   \n","4  ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω...   \n","\n","                                   original_sentence predicted_tokens  \n","0  ὅστις μέν σύ ὦ ἀνήρ Ἀθηναῖος πάσχω ὑπό ὁ ἐμός ...       [σωκρατης]  \n","1  ἐγώ δέ οὖν καί αὐτός ὑπό αὐτός ὀλίγος ἐμαυτοῦ ...            [και]  \n","2          καίτοι ἀληθής γε ὡς ἔπος εἶπον οὐδείς ἐρῶ         [ουδεις]  \n","3  μάλιστα δέ αὐτός εἷς θαυμάζω ὁ πολύς ὅς ψεύδω ...             [γε]  \n","4  ὁ γάρ μή αἰσχύνω ὅστις αὐτίκα ὑπό ἐγώ ἐξελέγχω...           [λεγω]  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# extract predictions for each masked sentence\n","predictions = []\n","\n","for sentence in input:\n","    # tokenize the sentence and find the index of the masked token\n","    tokenized_text = tokenizer.tokenize(sentence)\n","    masked_index = tokenized_text.index(\"[MASK]\")\n","\n","    # convert the tokenized sentence to input ids and create a tensor of input ids\n","    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n","    input_ids = torch.tensor([input_ids])\n","\n","    # use the model to make predictions on the masked token\n","    with torch.no_grad():\n","        outputs = model(input_ids.to(device))\n","        predictions.append(outputs[0][0, masked_index].topk(k=1))\n","      \n","\n","# convert the predicted token ids to tokens\n","predicted_tokens = [tokenizer.convert_ids_to_tokens(pred.indices.tolist()) for pred in predictions]\n","\n","# create a dataframe with the context sentences, masked sentences, original sentences, and predicted tokens\n","output = pd.DataFrame({\n","    'context_sentence': [' '.join(sentence.split()[:-1]) for sentence in y_hat],\n","    'masked_sentence': input,\n","    'original_sentence': y_hat,\n","    'predicted_tokens': predicted_tokens,\n","})\n","\n","# print the output dataframe\n","output.head(5)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T13:02:39.112123Z","iopub.status.busy":"2023-04-04T13:02:39.111415Z","iopub.status.idle":"2023-04-04T13:02:40.006644Z","shell.execute_reply":"2023-04-04T13:02:40.005476Z","shell.execute_reply.started":"2023-04-04T13:02:39.112084Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"bert.pt\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
